{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9712282,"sourceType":"datasetVersion","datasetId":5940979},{"sourceId":9712335,"sourceType":"datasetVersion","datasetId":5941025}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T17:33:23.604056Z","iopub.execute_input":"2024-10-28T17:33:23.604908Z","iopub.status.idle":"2024-10-28T17:33:24.013425Z","shell.execute_reply.started":"2024-10-28T17:33:23.604859Z","shell.execute_reply":"2024-10-28T17:33:24.012487Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/hackathon-data-clear/data.pkl\n/kaggle/input/hackathon-data/data_not_clean.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n! pip install transformers sentencepiece","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-10-28T17:33:26.676197Z","iopub.execute_input":"2024-10-28T17:33:26.677067Z","iopub.status.idle":"2024-10-28T17:33:38.650239Z","shell.execute_reply.started":"2024-10-28T17:33:26.677027Z","shell.execute_reply":"2024-10-28T17:33:38.648971Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%%capture\n!git lfs install\n!git clone https://huggingface.co/cointegrated/rubert-tiny2","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:33:57.458163Z","iopub.execute_input":"2024-10-28T17:33:57.459011Z","iopub.status.idle":"2024-10-28T17:33:59.452899Z","shell.execute_reply.started":"2024-10-28T17:33:57.458967Z","shell.execute_reply":"2024-10-28T17:33:59.451645Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom collections import OrderedDict\nfrom transformers import AutoTokenizer, AutoModel","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:34:01.285108Z","iopub.execute_input":"2024-10-28T17:34:01.285906Z","iopub.status.idle":"2024-10-28T17:34:03.847188Z","shell.execute_reply.started":"2024-10-28T17:34:01.285859Z","shell.execute_reply":"2024-10-28T17:34:03.846320Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed = 42\nset_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:35:02.215085Z","iopub.execute_input":"2024-10-28T17:35:02.215718Z","iopub.status.idle":"2024-10-28T17:35:02.223975Z","shell.execute_reply.started":"2024-10-28T17:35:02.215673Z","shell.execute_reply":"2024-10-28T17:35:02.223111Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:35:04.724601Z","iopub.execute_input":"2024-10-28T17:35:04.724992Z","iopub.status.idle":"2024-10-28T17:35:04.760327Z","shell.execute_reply.started":"2024-10-28T17:35:04.724956Z","shell.execute_reply":"2024-10-28T17:35:04.759127Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nnum_epochs = 100\nbatch_size = 32\nlearning_rate = 1e-5","metadata":{"execution":{"iopub.status.busy":"2024-10-28T18:42:18.032849Z","iopub.execute_input":"2024-10-28T18:42:18.033719Z","iopub.status.idle":"2024-10-28T18:42:18.038052Z","shell.execute_reply.started":"2024-10-28T18:42:18.033677Z","shell.execute_reply":"2024-10-28T18:42:18.037092Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n        self.base = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n        n_dim = 312\n        self.head = nn.Sequential(OrderedDict( [('dropout', torch.nn.Dropout(.2)),\n                                                ('fc_1' , nn.Linear(n_dim, n_dim*2)),\n                                                ('relu_1' , nn.ReLU()),\n                                                ('batchnorm_1' , nn.BatchNorm1d(n_dim*2, eps=1e-12)),\n                                                ('fc_2' , nn.Linear(n_dim*2, n_dim)),\n                                                ('relu_2' , nn.ReLU()),\n                                                ('batchnorm_2' , nn.BatchNorm1d(n_dim, eps=1e-12)),\n                                                ('fc_3' , nn.Linear(n_dim, 2, bias=False))\n                    ]))\n\n    def forward(self, tokens):\n        model_output = self.base(**tokens)\n        result = self.head(model_output.pooler_output)\n        return result\n    \n    def get_loss(self, texts, labels):\n        # нужно дублировать метки, потому что на последнем слое 2 нейрона\n        inv_labels = torch.ones(labels.shape) - labels\n        targets = torch.stack((labels, inv_labels), dim=1).detach().clone().to(device)\n        \n        # токенизация и форвард-пасс\n        tokens = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n        outputs = self.forward(tokens)\n        \n        return criterion(outputs, targets)\n    \n    def eval_loss(self, dataloader):\n        batch_indx = np.random.randint(len(dataloader)+1, size=batch_size)\n        batch_texts = [dataloader.dataset[i][0] for i in batch_indx]\n        batch_labels = torch.Tensor([train_dataloader.dataset[i][1] for i in batch_indx])\n        return self.get_loss(batch_texts, batch_labels).item()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:35:21.908718Z","iopub.execute_input":"2024-10-28T17:35:21.909608Z","iopub.status.idle":"2024-10-28T17:35:21.922184Z","shell.execute_reply.started":"2024-10-28T17:35:21.909555Z","shell.execute_reply":"2024-10-28T17:35:21.921069Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# model_path = './CrossEncoderModel'\nmodel = Model().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:39:38.006035Z","iopub.execute_input":"2024-10-28T17:39:38.006526Z","iopub.status.idle":"2024-10-28T17:39:38.396412Z","shell.execute_reply.started":"2024-10-28T17:39:38.006478Z","shell.execute_reply":"2024-10-28T17:39:38.395319Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Unpickle dataset\ndf = pd.read_pickle('/kaggle/input/hackathon-data/data_not_clean.pkl')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:35:28.750216Z","iopub.execute_input":"2024-10-28T17:35:28.750809Z","iopub.status.idle":"2024-10-28T17:35:30.094025Z","shell.execute_reply.started":"2024-10-28T17:35:28.750763Z","shell.execute_reply":"2024-10-28T17:35:30.092857Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                               query  \\\n0  Когда был спущен на воду первый миноносец «Спо...   \n1  Как долго существовало британское телевизионно...   \n2          Когда родилась Князева Марина Леонидовна?   \n3               Кто был главным художником мира Зен?   \n4    Как звали предполагаемого убийцу Джона Кеннеди?   \n\n                                                text  label  \\\n0  Зачислен в списки ВМФ СССР 19 августа 1952 год...      1   \n1  Хрустальный лабиринт (\"The Crystal Maze\") — бр...      1   \n2  Князева Марина Леонидовна (род. 7 мая 1952 г.)...      1   \n3  В книге \"Half-Life 2: Raising the Bar\" художни...      1   \n4  В 1966 году окружной прокурор Нового Орлеана Д...      1   \n\n                                          clean_text  \\\n0  Зачислен в списки ВМФ СССР 19 августа 1952 год...   \n1  Хрустальный лабиринт (\"The Crystal Maze\") — бр...   \n2  Князева Марина Леонидовна (род. 7 мая 1952 г.)...   \n3  В книге \"Half-Life 2: Raising the Bar\" художни...   \n4  В 1966 году окружной прокурор Нового Орлеана Д...   \n\n                                         clean_query  \\\n0  Когда был спущен на воду первый миноносец «Спо...   \n1  Как долго существовало британское телевизионно...   \n2          Когда родилась Князева Марина Леонидовна?   \n3               Кто был главным художником мира Зен?   \n4    Как звали предполагаемого убийцу Джона Кеннеди?   \n\n                                      embedding_text  \\\n0  [-0.0030975677, -0.018142669, -0.0058722952, 0...   \n1  [0.0026477594, -0.026646728, 0.0009579654, -0....   \n2  [-0.036747612, -0.012604811, -0.0109199695, -0...   \n3  [-0.02514373, -0.023727695, -0.04738828, 0.011...   \n4  [0.0074619167, -0.024880972, -0.026498705, 0.0...   \n\n                                     embedding_query  \n0  [0.00064380514, 0.0074218363, -0.03353223, -0....  \n1  [-0.029795218, -0.01173853, -0.00032150946, -0...  \n2  [-0.036575466, -0.010551005, -0.04117768, -0.0...  \n3  [-0.022960061, -0.013048667, -0.018877652, -0....  \n4  [-0.0124044325, -0.0020067864, -0.030558525, 0...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query</th>\n      <th>text</th>\n      <th>label</th>\n      <th>clean_text</th>\n      <th>clean_query</th>\n      <th>embedding_text</th>\n      <th>embedding_query</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Когда был спущен на воду первый миноносец «Спо...</td>\n      <td>Зачислен в списки ВМФ СССР 19 августа 1952 год...</td>\n      <td>1</td>\n      <td>Зачислен в списки ВМФ СССР 19 августа 1952 год...</td>\n      <td>Когда был спущен на воду первый миноносец «Спо...</td>\n      <td>[-0.0030975677, -0.018142669, -0.0058722952, 0...</td>\n      <td>[0.00064380514, 0.0074218363, -0.03353223, -0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Как долго существовало британское телевизионно...</td>\n      <td>Хрустальный лабиринт (\"The Crystal Maze\") — бр...</td>\n      <td>1</td>\n      <td>Хрустальный лабиринт (\"The Crystal Maze\") — бр...</td>\n      <td>Как долго существовало британское телевизионно...</td>\n      <td>[0.0026477594, -0.026646728, 0.0009579654, -0....</td>\n      <td>[-0.029795218, -0.01173853, -0.00032150946, -0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Когда родилась Князева Марина Леонидовна?</td>\n      <td>Князева Марина Леонидовна (род. 7 мая 1952 г.)...</td>\n      <td>1</td>\n      <td>Князева Марина Леонидовна (род. 7 мая 1952 г.)...</td>\n      <td>Когда родилась Князева Марина Леонидовна?</td>\n      <td>[-0.036747612, -0.012604811, -0.0109199695, -0...</td>\n      <td>[-0.036575466, -0.010551005, -0.04117768, -0.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Кто был главным художником мира Зен?</td>\n      <td>В книге \"Half-Life 2: Raising the Bar\" художни...</td>\n      <td>1</td>\n      <td>В книге \"Half-Life 2: Raising the Bar\" художни...</td>\n      <td>Кто был главным художником мира Зен?</td>\n      <td>[-0.02514373, -0.023727695, -0.04738828, 0.011...</td>\n      <td>[-0.022960061, -0.013048667, -0.018877652, -0....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Как звали предполагаемого убийцу Джона Кеннеди?</td>\n      <td>В 1966 году окружной прокурор Нового Орлеана Д...</td>\n      <td>1</td>\n      <td>В 1966 году окружной прокурор Нового Орлеана Д...</td>\n      <td>Как звали предполагаемого убийцу Джона Кеннеди?</td>\n      <td>[0.0074619167, -0.024880972, -0.026498705, 0.0...</td>\n      <td>[-0.0124044325, -0.0020067864, -0.030558525, 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Train-test split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split((df['clean_query']+' [SEP] '+df['clean_text']).to_numpy(), df['label'].to_numpy(), test_size=0.2, random_state=seed)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:35:32.938374Z","iopub.execute_input":"2024-10-28T17:35:32.939178Z","iopub.status.idle":"2024-10-28T17:35:33.509397Z","shell.execute_reply.started":"2024-10-28T17:35:32.939136Z","shell.execute_reply":"2024-10-28T17:35:33.508440Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((37607,), (9402,))"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass PandasDataset(Dataset):\n    def __init__(self, df):\n        self.dataframe = df.reset_index()\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        return list(self.dataframe.iloc[index])[1:]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:35:36.956667Z","iopub.execute_input":"2024-10-28T17:35:36.957247Z","iopub.status.idle":"2024-10-28T17:35:36.966402Z","shell.execute_reply.started":"2024-10-28T17:35:36.957207Z","shell.execute_reply":"2024-10-28T17:35:36.965371Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_dataloader = DataLoader(PandasDataset(pd.DataFrame([X_train, y_train]).T),\n                              batch_size=batch_size)\ntest_dataloader = DataLoader(PandasDataset(pd.DataFrame([X_test, y_test]).T),\n                              batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T18:42:55.375928Z","iopub.execute_input":"2024-10-28T18:42:55.376780Z","iopub.status.idle":"2024-10-28T18:42:57.116194Z","shell.execute_reply.started":"2024-10-28T18:42:55.376741Z","shell.execute_reply":"2024-10-28T18:42:57.115114Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.008)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T18:42:59.372811Z","iopub.execute_input":"2024-10-28T18:42:59.373708Z","iopub.status.idle":"2024-10-28T18:42:59.379751Z","shell.execute_reply.started":"2024-10-28T18:42:59.373664Z","shell.execute_reply":"2024-10-28T18:42:59.378808Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Uncomment to train model\ntotal_step = len(train_dataloader)\n\nbest_val_loss = 10**8\ntrain_losses_history = []\ntest_losses_history = []\nfor epoch in range(num_epochs):\n    model.train()\n    for i, (texts, labels) in enumerate(train_dataloader):\n        # Forward pass\n        loss = model.get_loss(texts, labels)\n        \n        # Backprpagation and optimizer step\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n        optimizer.step()\n        # print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n    \n    model.eval()\n    train_loss = model.eval_loss(train_dataloader)\n    test_loss = model.eval_loss(test_dataloader)\n    print(f'\\n Epoch [{epoch + 1}/{num_epochs}], Train Loss [{train_loss:.4f}], Test Loss [{test_loss:.4f}]')\n    train_losses_history.append(train_loss)\n    test_losses_history.append(test_loss)\n    if test_loss <= best_val_loss:\n        best_val_loss = test_loss\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': best_val_loss,\n        }, 'model.ckpt')\n\n\ntorch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': best_val_loss,\n}, 'model_final.ckpt')\ntorch.save(torch.Tensor(train_losses_history), 'train_loss_history')\ntorch.save(torch.Tensor(test_losses_history), 'test_loss_history')","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:39:45.270668Z","iopub.execute_input":"2024-10-28T17:39:45.271541Z","iopub.status.idle":"2024-10-28T18:42:03.314727Z","shell.execute_reply.started":"2024-10-28T17:39:45.271488Z","shell.execute_reply":"2024-10-28T18:42:03.313291Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\n Epoch [1/100], Train Loss [0.8446], Test Loss [0.8621]\n\n Epoch [2/100], Train Loss [0.8018], Test Loss [0.8557]\n\n Epoch [3/100], Train Loss [0.7697], Test Loss [0.7401]\n\n Epoch [4/100], Train Loss [0.7392], Test Loss [0.7908]\n\n Epoch [5/100], Train Loss [0.7734], Test Loss [0.8139]\n\n Epoch [6/100], Train Loss [0.7930], Test Loss [0.7912]\n\n Epoch [7/100], Train Loss [0.6612], Test Loss [0.7917]\n\n Epoch [8/100], Train Loss [0.7992], Test Loss [0.8307]\n\n Epoch [9/100], Train Loss [0.8177], Test Loss [0.7529]\n\n Epoch [10/100], Train Loss [0.6989], Test Loss [0.7407]\n\n Epoch [11/100], Train Loss [0.7657], Test Loss [0.7390]\n\n Epoch [12/100], Train Loss [0.8290], Test Loss [0.8784]\n\n Epoch [13/100], Train Loss [0.8295], Test Loss [0.7477]\n\n Epoch [14/100], Train Loss [0.8177], Test Loss [0.7915]\n\n Epoch [15/100], Train Loss [0.7102], Test Loss [0.8527]\n\n Epoch [16/100], Train Loss [0.7387], Test Loss [0.7798]\n\n Epoch [17/100], Train Loss [0.7215], Test Loss [0.8109]\n\n Epoch [18/100], Train Loss [0.7349], Test Loss [0.8152]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (texts, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Backprpagation and optimizer step\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36mModel.get_loss\u001b[0;34m(self, texts, labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts, labels):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# нужно дублировать метки, потому что на последнем слое 2 нейрона\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     inv_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(labels\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m labels\n\u001b[0;32m---> 25\u001b[0m     targets \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# токенизация и форвард-пасс\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(texts, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Uncomment to test the model\n# with torch.no_grad():\n#     correct = 0\n#     total = 0\n#     for texts, labels in test_dataloader:\n#         labels = labels.to(device)\n#         tokens = model.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n#         outputs = model(tokens)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n\n#     print(f'Accuracy: {100 * correct / total} %')\n\n# # Save the model checkpoint\n# torch.save(model.state_dict(), 'model.ckpt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}