{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9712282,"sourceType":"datasetVersion","datasetId":5940979},{"sourceId":9712335,"sourceType":"datasetVersion","datasetId":5941025},{"sourceId":9752334,"sourceType":"datasetVersion","datasetId":5970936},{"sourceId":151495,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":128654,"modelId":151527}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-02T09:24:42.017540Z","iopub.status.idle":"2024-11-02T09:24:42.017947Z","shell.execute_reply.started":"2024-11-02T09:24:42.017728Z","shell.execute_reply":"2024-11-02T09:24:42.017746Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n! pip install transformers sentencepiece","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-11-02T09:24:42.019133Z","iopub.status.idle":"2024-11-02T09:24:42.019507Z","shell.execute_reply.started":"2024-11-02T09:24:42.019320Z","shell.execute_reply":"2024-11-02T09:24:42.019339Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n!git lfs install\n!git clone https://huggingface.co/cointegrated/rubert-tiny2","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.020879Z","iopub.status.idle":"2024-11-02T09:24:42.021283Z","shell.execute_reply.started":"2024-11-02T09:24:42.021088Z","shell.execute_reply":"2024-11-02T09:24:42.021107Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom collections import OrderedDict\nfrom transformers import AutoTokenizer, AutoModel","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.022218Z","iopub.status.idle":"2024-11-02T09:24:42.022574Z","shell.execute_reply.started":"2024-11-02T09:24:42.022395Z","shell.execute_reply":"2024-11-02T09:24:42.022414Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed = 42\nset_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.024137Z","iopub.status.idle":"2024-11-02T09:24:42.024476Z","shell.execute_reply.started":"2024-11-02T09:24:42.024302Z","shell.execute_reply":"2024-11-02T09:24:42.024319Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.026363Z","iopub.status.idle":"2024-11-02T09:24:42.026731Z","shell.execute_reply.started":"2024-11-02T09:24:42.026552Z","shell.execute_reply":"2024-11-02T09:24:42.026570Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nnum_epochs = 15\nbatch_size = 64\nlearning_rate = 1e-4","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.028310Z","iopub.status.idle":"2024-11-02T09:24:42.028673Z","shell.execute_reply.started":"2024-11-02T09:24:42.028497Z","shell.execute_reply":"2024-11-02T09:24:42.028515Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n        self.base = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n\n        # freezing base model weights\n        for param in self.base.parameters():\n            param.requires_grad = False\n\n        n_dim = 312\n        self.head = nn.Sequential(OrderedDict( [('dropout', torch.nn.Dropout(.2)),\n                                                ('fc_1' , nn.Linear(n_dim, n_dim//2)),\n                                                ('relu_1' , nn.ReLU()),\n                                                ('batchnorm_1' , nn.BatchNorm1d(n_dim//2, eps=1e-12)),\n                                                ('dropout', torch.nn.Dropout(.2)),\n                                                ('fc_3' , nn.Linear(n_dim//2, 2, bias=False))\n                    ]))\n\n    def forward(self, tokens):\n        model_output = self.base(**tokens)\n        result = self.head(model_output.pooler_output)\n        return result\n    \n    def get_loss(self, texts, labels):\n        targets = labels.long().to(device)  # Convert labels to long integers\n        tokens = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n        outputs = self.forward(tokens)\n        return criterion(outputs, targets)\n    \n    def eval_loss(self, dataloader):\n        batch_indx = np.random.randint(len(dataloader)+1, size=batch_size)\n        batch_texts = [dataloader.dataset[i][0] for i in batch_indx]\n        batch_labels = torch.Tensor([train_dataloader.dataset[i][1] for i in batch_indx])\n        return self.get_loss(batch_texts, batch_labels).item()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.029664Z","iopub.status.idle":"2024-11-02T09:24:42.030051Z","shell.execute_reply.started":"2024-11-02T09:24:42.029865Z","shell.execute_reply":"2024-11-02T09:24:42.029888Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model_path = './CrossEncoderModel'\nmodel = Model().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.031529Z","iopub.status.idle":"2024-11-02T09:24:42.031943Z","shell.execute_reply.started":"2024-11-02T09:24:42.031732Z","shell.execute_reply":"2024-11-02T09:24:42.031751Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unpickle dataset\ndf = pd.read_pickle('/kaggle/input/data-not-clean1/data_not_clean1.pkl')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.032883Z","iopub.status.idle":"2024-11-02T09:24:42.033232Z","shell.execute_reply.started":"2024-11-02T09:24:42.033060Z","shell.execute_reply":"2024-11-02T09:24:42.033077Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-test split\n\nfrom sklearn.model_selection import train_test_split\n\ndf_filtered = df[['clean_query', 'clean_text', 'label']]\n\n# Группируем по запросам\ngrouped = df_filtered.groupby('clean_query').agg({'clean_text': list, 'label': list}).reset_index()\n\ntrain, test_val = train_test_split(grouped, test_size=0.2, random_state=42)\n\n# Разворачиваем списки текстов и меток обратно в строки для каждой подвыборки\ntrain = train.explode(['clean_text', 'label']).reset_index(drop=True)\ntest_val = test_val.explode(['clean_text', 'label']).reset_index(drop=True)\n\n# Проверка результата\nprint(\"Train size:\", len(train))\nprint(\"Test/Validation size:\", len(test_val))","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.034655Z","iopub.status.idle":"2024-11-02T09:24:42.035063Z","shell.execute_reply.started":"2024-11-02T09:24:42.034857Z","shell.execute_reply":"2024-11-02T09:24:42.034886Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.036216Z","iopub.status.idle":"2024-11-02T09:24:42.036599Z","shell.execute_reply.started":"2024-11-02T09:24:42.036403Z","shell.execute_reply":"2024-11-02T09:24:42.036422Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, y_train  = (train['clean_query']+' [SEP] '+train['clean_text']).to_numpy(), train['label'].to_numpy()\nX_test, y_test = (test_val['clean_query']+' [SEP] '+test_val['clean_text']).to_numpy(), test_val['label'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.037893Z","iopub.status.idle":"2024-11-02T09:24:42.038246Z","shell.execute_reply.started":"2024-11-02T09:24:42.038071Z","shell.execute_reply":"2024-11-02T09:24:42.038089Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass PandasDataset(Dataset):\n    def __init__(self, df):\n        self.dataframe = df.reset_index()\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        return list(self.dataframe.iloc[index])[1:]","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.039282Z","iopub.status.idle":"2024-11-02T09:24:42.039786Z","shell.execute_reply.started":"2024-11-02T09:24:42.039597Z","shell.execute_reply":"2024-11-02T09:24:42.039617Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_dataloader = DataLoader(PandasDataset(pd.DataFrame([X_train, y_train]).T),\n                              batch_size=batch_size)\ntest_dataloader = DataLoader(PandasDataset(pd.DataFrame([X_test, y_test]).T),\n                              batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.041152Z","iopub.status.idle":"2024-11-02T09:24:42.041713Z","shell.execute_reply.started":"2024-11-02T09:24:42.041440Z","shell.execute_reply":"2024-11-02T09:24:42.041469Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nnum_epochs = 6\nbatch_size = 64\nlearning_rate = 1e-4\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.008)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.042775Z","iopub.status.idle":"2024-11-02T09:24:42.043237Z","shell.execute_reply.started":"2024-11-02T09:24:42.042989Z","shell.execute_reply":"2024-11-02T09:24:42.043016Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\n# Training loop\ntotal_step = len(train_dataloader)\nbest_val_loss = float('inf')\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_start_time = time.time()  # Start timing the epoch\n    train_loss = 0.0\n    for texts, labels in train_dataloader:\n        loss = model.get_loss(texts, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n        optimizer.step()\n        train_loss += loss.item() * len(texts)  # Accumulate loss\n\n    train_loss /= len(train_dataloader.dataset)  # Compute average loss\n\n    # Evaluate loss after each epoch\n    model.eval()\n    with torch.no_grad():\n        test_loss = sum(model.get_loss(batch[0], batch[1]).item() * len(batch[0]) for batch in test_dataloader) / len(test_dataloader.dataset)\n\n    if test_loss < best_val_loss:\n        best_val_loss = test_loss\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'epoch': epoch,\n            'loss': loss\n        }, 'best_model.ckpt')\n        print('\\nsave_model\\n')\n\n    epoch_duration = time.time() - epoch_start_time  # Calculate epoch duration\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Time: {epoch_duration:.2f} seconds')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:31:25.150389Z","iopub.execute_input":"2024-10-30T13:31:25.150769Z","iopub.status.idle":"2024-10-30T13:42:38.006017Z","shell.execute_reply.started":"2024-10-30T13:31:25.150732Z","shell.execute_reply":"2024-10-30T13:42:38.005044Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nsave_model\n\nEpoch [1/6], Train Loss: 0.6711, Test Loss: 0.6022, Time: 112.27 seconds\n\nsave_model\n\nEpoch [2/6], Train Loss: 0.6007, Test Loss: 0.5825, Time: 112.13 seconds\n\nsave_model\n\nEpoch [3/6], Train Loss: 0.5830, Test Loss: 0.5812, Time: 112.10 seconds\n\nsave_model\n\nEpoch [4/6], Train Loss: 0.5781, Test Loss: 0.5811, Time: 112.23 seconds\n\nsave_model\n\nEpoch [5/6], Train Loss: 0.5733, Test Loss: 0.5789, Time: 112.28 seconds\nEpoch [6/6], Train Loss: 0.5720, Test Loss: 0.5796, Time: 111.84 seconds\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model2 = Model().to(device)\n\ncheckpoint = torch.load('/kaggle/input/to_fine_tuning/pytorch/default/1/best_model.ckpt', weights_only=True)\n\nmodel2.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\n# Если вы планируете использовать модель для обучения\n#model.train()\n\n# Или если планируете использовать только для инференса\nmodel2.eval()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:24:42.044629Z","iopub.status.idle":"2024-11-02T09:24:42.045044Z","shell.execute_reply.started":"2024-11-02T09:24:42.044815Z","shell.execute_reply":"2024-11-02T09:24:42.044853Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def testing(model_f):\n    correct, total = 0, 0\n    with torch.no_grad():\n        for texts, labels in test_dataloader:\n            labels = labels.to(device).long() # Crucial: Convert labels to long\n            tokens = model_f.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n            outputs = model_f(tokens)\n            _, predicted = torch.max(outputs, 1) # Correct way to get predictions\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        print(f'Accuracy: {100 * correct / total:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T18:47:14.630143Z","iopub.execute_input":"2024-10-30T18:47:14.631081Z","iopub.status.idle":"2024-10-30T18:47:14.637456Z","shell.execute_reply.started":"2024-10-30T18:47:14.631038Z","shell.execute_reply":"2024-10-30T18:47:14.636500Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"testing(model)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testing(model2)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T18:47:16.489101Z","iopub.execute_input":"2024-10-30T18:47:16.489499Z","iopub.status.idle":"2024-10-30T18:47:37.073731Z","shell.execute_reply.started":"2024-10-30T18:47:16.489462Z","shell.execute_reply":"2024-10-30T18:47:37.072554Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy: 71.74%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Ranking","metadata":{}},{"cell_type":"code","source":"def custom_metric(df_sorted):\n    n = len(df_sorted)\n    k = df_sorted['label'].sum()\n    if k == 0:\n        return 1\n    top_k = max(3, int(k))\n    \n    top_k_answers = df_sorted.iloc[:top_k]\n    \n    correct_in_top_k = top_k_answers['label'].sum()\n    \n    score = correct_in_top_k / k\n    return score\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T14:56:46.375400Z","iopub.execute_input":"2024-11-01T14:56:46.375811Z","iopub.status.idle":"2024-11-01T14:56:46.382427Z","shell.execute_reply.started":"2024-11-01T14:56:46.375774Z","shell.execute_reply":"2024-11-01T14:56:46.381323Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def metric_with_weight(df_sorted):\n    n = len(df_sorted)\n    k = df_sorted['label'].sum()\n\n    if k == 0:\n        return 1\n    \n    # Количество позиций для оценки\n    top_k = max(3, int(k))\n\n    # Отбираем первые top_k ответов после ранжирования\n    top_k_answers = df_sorted.iloc[:top_k]\n    \n    # Считаем количество правильных ответов среди первых top_k\n    correct_in_top_k = top_k_answers['label'].sum()\n\n    # Рассчитываем процент правильных ответов среди первых top_k\n    base_score = correct_in_top_k / k\n\n    # Уверенность модели - добавляем веса на основе отклонения similarity от среднего\n    avg_similarity = df_sorted['relevance'].mean()\n    similarity_deviation = abs(df_sorted['relevance'] - avg_similarity)\n\n    # Присваиваем вес каждому ответу: чем больше отклонение от среднего, тем больше вес\n    weights = 1 + similarity_deviation / avg_similarity\n\n    # Применяем веса к правильным ответам в первых top_k позициях\n    weighted_correct_in_top_k = (top_k_answers['label'] * weights[:top_k]).sum()\n\n    # Рассчитываем итоговый score с учетом весов\n    weighted_score = weighted_correct_in_top_k / k\n\n    return weighted_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T14:58:14.562952Z","iopub.execute_input":"2024-11-01T14:58:14.563360Z","iopub.status.idle":"2024-11-01T14:58:14.571611Z","shell.execute_reply.started":"2024-11-01T14:58:14.563323Z","shell.execute_reply":"2024-11-01T14:58:14.570412Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def metric_first_true(df_sorted):\n    n = len(df_sorted)\n    k = df_sorted['label'].sum()\n\n    if k == 0:\n        return 1\n    for i in range(n):\n        if df_sorted['label'][i]==1:\n            return i+1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T14:58:14.678802Z","iopub.execute_input":"2024-11-01T14:58:14.679525Z","iopub.status.idle":"2024-11-01T14:58:14.685456Z","shell.execute_reply.started":"2024-11-01T14:58:14.679480Z","shell.execute_reply":"2024-11-01T14:58:14.684113Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def rank_answers_by_relevance(df, model_f):\n    relevance_scores = []\n    \n    for _, row in df.iterrows():\n        query = row['clean_query']\n        answer = row['clean_text']\n        \n        inputs = model_f.tokenizer(\n            query,\n            answer,\n            add_special_tokens=True,\n            return_tensors='pt',\n            max_length=512,\n            truncation=True,\n            padding='max_length'\n        ).to(device)\n\n        with torch.no_grad():\n            outputs = model_f(inputs)\n            relevance_score = torch.softmax(outputs, dim=1)[0][1].item()\n            relevance_scores.append(relevance_score)\n    \n    df['relevance'] = relevance_scores\n    df_sorted = df.sort_values(by='relevance', ascending=False).reset_index(drop=True)\n    \n    return df_sorted\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T14:58:14.898269Z","iopub.execute_input":"2024-11-01T14:58:14.898970Z","iopub.status.idle":"2024-11-01T14:58:14.907315Z","shell.execute_reply.started":"2024-11-01T14:58:14.898927Z","shell.execute_reply":"2024-11-01T14:58:14.906309Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"\nres = []\nfor query, text in df.groupby('clean_query'):\n    ranked_df = rank_answers_by_relevance(text, model2)\n    score1 = custom_metric(ranked_df)\n    score2 = metric_with_weight(ranked_df)\n    score3 = metric_first_true(ranked_df)\n    n = len(ranked_df)\n    k = ranked_df['label'].sum()\n    res.append([query, score1, score2, score3, n, k])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T14:58:15.481712Z","iopub.execute_input":"2024-11-01T14:58:15.482140Z","iopub.status.idle":"2024-11-01T15:02:43.569096Z","shell.execute_reply.started":"2024-11-01T14:58:15.482100Z","shell.execute_reply":"2024-11-01T15:02:43.567944Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"summ_score1 = sum([elem[1] for elem in res]) / len(res)\nsumm_score2 = sum([elem[2] for elem in res]) / len(res)\nsumm_score3 = sum([elem[3] for elem in res]) / len(res)\nprint(\"Average Score:\", summ_score1,summ_score2,summ_score3 )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T15:02:43.571157Z","iopub.execute_input":"2024-11-01T15:02:43.571590Z","iopub.status.idle":"2024-11-01T15:02:43.583784Z","shell.execute_reply.started":"2024-11-01T15:02:43.571549Z","shell.execute_reply":"2024-11-01T15:02:43.582730Z"}},"outputs":[{"name":"stdout","text":"Average Score: 0.618837995646903 0.8999355470062163 2.447292966773486\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"Неожиданно metric_with_weight побила baseline результаты!!!!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T09:25:19.837345Z","iopub.execute_input":"2024-11-02T09:25:19.837748Z","iopub.status.idle":"2024-11-02T09:25:19.844099Z","shell.execute_reply.started":"2024-11-02T09:25:19.837714Z","shell.execute_reply":"2024-11-02T09:25:19.842748Z"}},"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Неожиданно metric_with_weight побила baseline результаты!!!!\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3874190903.py, line 1)","output_type":"error"}],"execution_count":3}]}