{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9712282,"sourceType":"datasetVersion","datasetId":5940979},{"sourceId":9712335,"sourceType":"datasetVersion","datasetId":5941025},{"sourceId":9752334,"sourceType":"datasetVersion","datasetId":5970936},{"sourceId":9773826,"sourceType":"datasetVersion","datasetId":5987004},{"sourceId":151495,"sourceType":"modelInstanceVersion","modelInstanceId":128654,"modelId":151527}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install transformers sentencepiece","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-10-31T16:29:42.962284Z","iopub.execute_input":"2024-10-31T16:29:42.962583Z","iopub.status.idle":"2024-10-31T16:29:56.428503Z","shell.execute_reply.started":"2024-10-31T16:29:42.962550Z","shell.execute_reply":"2024-10-31T16:29:56.427130Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}]},{"cell_type":"code","source":"!git lfs install\n!git clone https://huggingface.co/cointegrated/rubert-tiny2","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:29:56.431121Z","iopub.execute_input":"2024-10-31T16:29:56.431647Z","iopub.status.idle":"2024-10-31T16:30:01.166747Z","shell.execute_reply.started":"2024-10-31T16:29:56.431574Z","shell.execute_reply":"2024-10-31T16:30:01.165602Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Git LFS initialized.\nCloning into 'rubert-tiny2'...\nremote: Enumerating objects: 59, done.\u001b[K\nremote: Total 59 (delta 0), reused 0 (delta 0), pack-reused 59 (from 1)\u001b[K\nUnpacking objects: 100% (59/59), 985.64 KiB | 7.88 MiB/s, done.\nFiltering content: 100% (3/3), 225.10 MiB | 123.53 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom collections import OrderedDict\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:30:01.168133Z","iopub.execute_input":"2024-10-31T16:30:01.168463Z","iopub.status.idle":"2024-10-31T16:30:20.465053Z","shell.execute_reply.started":"2024-10-31T16:30:01.168427Z","shell.execute_reply":"2024-10-31T16:30:20.464230Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed = 42\nset_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:30:20.467071Z","iopub.execute_input":"2024-10-31T16:30:20.467616Z","iopub.status.idle":"2024-10-31T16:30:20.478407Z","shell.execute_reply.started":"2024-10-31T16:30:20.467583Z","shell.execute_reply":"2024-10-31T16:30:20.477416Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:30:20.480145Z","iopub.execute_input":"2024-10-31T16:30:20.480542Z","iopub.status.idle":"2024-10-31T16:30:20.561593Z","shell.execute_reply.started":"2024-10-31T16:30:20.480496Z","shell.execute_reply":"2024-10-31T16:30:20.560776Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n        self.base = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n\n        # freezing base model weights\n        for param in self.base.parameters():\n            param.requires_grad = False\n\n        n_dim = 312\n        self.head = nn.Sequential(OrderedDict( [('dropout', torch.nn.Dropout(.2)),\n                                                ('fc_1' , nn.Linear(n_dim, n_dim//2)),\n                                                ('relu_1' , nn.ReLU()),\n                                                ('batchnorm_1' , nn.BatchNorm1d(n_dim//2, eps=1e-12)),\n                                                ('dropout', torch.nn.Dropout(.2)),\n                                                ('fc_3' , nn.Linear(n_dim//2, 2, bias=False))\n                    ]))\n\n    def forward(self, tokens):\n        model_output = self.base(**tokens)\n        result = self.head(model_output.pooler_output)\n        return result\n    \n    def get_loss(self, texts, labels):\n        targets = labels.long().to(device)  # Convert labels to long integers\n        tokens = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n        outputs = self.forward(tokens)\n        return criterion(outputs, targets)\n    \n    def eval_loss(self, dataloader):\n        batch_indx = np.random.randint(len(dataloader)+1, size=batch_size)\n        batch_texts = [dataloader.dataset[i][0] for i in batch_indx]\n        batch_labels = torch.Tensor([train_dataloader.dataset[i][1] for i in batch_indx])\n        return self.get_loss(batch_texts, batch_labels).item()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:30:20.563058Z","iopub.execute_input":"2024-10-31T16:30:20.563404Z","iopub.status.idle":"2024-10-31T16:30:20.577201Z","shell.execute_reply.started":"2024-10-31T16:30:20.563362Z","shell.execute_reply":"2024-10-31T16:30:20.576393Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# model_path = './CrossEncoderModel'\nmodel = Model().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:30:20.579271Z","iopub.execute_input":"2024-10-31T16:30:20.579559Z","iopub.status.idle":"2024-10-31T16:30:24.260223Z","shell.execute_reply.started":"2024-10-31T16:30:20.579528Z","shell.execute_reply":"2024-10-31T16:30:24.259111Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/401 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6697a9d406584692b7cf6e4e53cbd436"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"643fdb64c5554233bc20c761e5fced5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.74M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280442397ad440b2bfe7493100306b26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b30111cc81d94c9a9b002031116fe710"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c56e9718fb0a4d679793e9926d497b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/118M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d9727aac6247acbb7d8ee882b0f188"}},"metadata":{}}]},{"cell_type":"code","source":"# Unpickle dataset\ndf = pd.read_pickle('/kaggle/input/dataset-qa-last/data_last.pkl')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:39:38.121081Z","iopub.execute_input":"2024-10-31T16:39:38.121532Z","iopub.status.idle":"2024-10-31T16:39:42.706901Z","shell.execute_reply.started":"2024-10-31T16:39:38.121493Z","shell.execute_reply":"2024-10-31T16:39:42.705860Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                               query  \\\n0  Когда был спущен на воду первый миноносец «Спо...   \n1  Как долго существовало британское телевизионно...   \n2          Когда родилась Князева Марина Леонидовна?   \n3               Кто был главным художником мира Зен?   \n4    Как звали предполагаемого убийцу Джона Кеннеди?   \n\n                                                text  label  \\\n0  Зачислен в списки ВМФ СССР 19 августа 1952 год...      1   \n1  Хрустальный лабиринт (\"The Crystal Maze\") — бр...      1   \n2  Князева Марина Леонидовна (род. 7 мая 1952 г.)...      1   \n3  В книге \"Half-Life 2: Raising the Bar\" художни...      1   \n4  В 1966 году окружной прокурор Нового Орлеана Д...      1   \n\n                                          clean_text  \\\n0  Зачислен в списки ВМФ СССР 19 августа 1952 год...   \n1  Хрустальный лабиринт (\"The Crystal Maze\") — бр...   \n2  Князева Марина Леонидовна (род. 7 мая 1952 г.)...   \n3  В книге \"Half-Life 2: Raising the Bar\" художни...   \n4  В 1966 году окружной прокурор Нового Орлеана Д...   \n\n                                         clean_query  \\\n0  Когда был спущен на воду первый миноносец «Спо...   \n1  Как долго существовало британское телевизионно...   \n2          Когда родилась Князева Марина Леонидовна?   \n3               Кто был главным художником мира Зен?   \n4    Как звали предполагаемого убийцу Джона Кеннеди?   \n\n                                      embedding_text  \\\n0  [-0.0030975677, -0.018142669, -0.0058722952, 0...   \n1  [0.0026477594, -0.026646728, 0.0009579654, -0....   \n2  [-0.036747612, -0.012604811, -0.0109199695, -0...   \n3  [-0.02514373, -0.023727695, -0.04738828, 0.011...   \n4  [0.0074619167, -0.024880972, -0.026498705, 0.0...   \n\n                                     embedding_query  \n0  [0.00064380514, 0.0074218363, -0.03353223, -0....  \n1  [-0.029795218, -0.01173853, -0.00032150946, -0...  \n2  [-0.036575466, -0.010551005, -0.04117768, -0.0...  \n3  [-0.022960061, -0.013048667, -0.018877652, -0....  \n4  [-0.0124044325, -0.0020067864, -0.030558525, 0...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query</th>\n      <th>text</th>\n      <th>label</th>\n      <th>clean_text</th>\n      <th>clean_query</th>\n      <th>embedding_text</th>\n      <th>embedding_query</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Когда был спущен на воду первый миноносец «Спо...</td>\n      <td>Зачислен в списки ВМФ СССР 19 августа 1952 год...</td>\n      <td>1</td>\n      <td>Зачислен в списки ВМФ СССР 19 августа 1952 год...</td>\n      <td>Когда был спущен на воду первый миноносец «Спо...</td>\n      <td>[-0.0030975677, -0.018142669, -0.0058722952, 0...</td>\n      <td>[0.00064380514, 0.0074218363, -0.03353223, -0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Как долго существовало британское телевизионно...</td>\n      <td>Хрустальный лабиринт (\"The Crystal Maze\") — бр...</td>\n      <td>1</td>\n      <td>Хрустальный лабиринт (\"The Crystal Maze\") — бр...</td>\n      <td>Как долго существовало британское телевизионно...</td>\n      <td>[0.0026477594, -0.026646728, 0.0009579654, -0....</td>\n      <td>[-0.029795218, -0.01173853, -0.00032150946, -0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Когда родилась Князева Марина Леонидовна?</td>\n      <td>Князева Марина Леонидовна (род. 7 мая 1952 г.)...</td>\n      <td>1</td>\n      <td>Князева Марина Леонидовна (род. 7 мая 1952 г.)...</td>\n      <td>Когда родилась Князева Марина Леонидовна?</td>\n      <td>[-0.036747612, -0.012604811, -0.0109199695, -0...</td>\n      <td>[-0.036575466, -0.010551005, -0.04117768, -0.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Кто был главным художником мира Зен?</td>\n      <td>В книге \"Half-Life 2: Raising the Bar\" художни...</td>\n      <td>1</td>\n      <td>В книге \"Half-Life 2: Raising the Bar\" художни...</td>\n      <td>Кто был главным художником мира Зен?</td>\n      <td>[-0.02514373, -0.023727695, -0.04738828, 0.011...</td>\n      <td>[-0.022960061, -0.013048667, -0.018877652, -0....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Как звали предполагаемого убийцу Джона Кеннеди?</td>\n      <td>В 1966 году окружной прокурор Нового Орлеана Д...</td>\n      <td>1</td>\n      <td>В 1966 году окружной прокурор Нового Орлеана Д...</td>\n      <td>Как звали предполагаемого убийцу Джона Кеннеди?</td>\n      <td>[0.0074619167, -0.024880972, -0.026498705, 0.0...</td>\n      <td>[-0.0124044325, -0.0020067864, -0.030558525, 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Train-test split\n\nfrom sklearn.model_selection import train_test_split\n\ndf_filtered = df[['clean_query', 'clean_text', 'label']]\n\n# Группируем по запросам\ngrouped = df_filtered.groupby('clean_query').agg({'clean_text': list, 'label': list}).reset_index()\n\ntrain, test_val = train_test_split(grouped, test_size=0.2, random_state=42)\n\n# Разворачиваем списки текстов и меток обратно в строки для каждой подвыборки\ntrain = train.explode(['clean_text', 'label']).reset_index(drop=True)\ntest_val = test_val.explode(['clean_text', 'label']).reset_index(drop=True)\n\n# Проверка результата\nprint(\"Train size:\", len(train))\nprint(\"Test/Validation size:\", len(test_val))","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:39:46.015959Z","iopub.execute_input":"2024-10-31T16:39:46.016337Z","iopub.status.idle":"2024-10-31T16:39:46.948110Z","shell.execute_reply.started":"2024-10-31T16:39:46.016302Z","shell.execute_reply":"2024-10-31T16:39:46.947102Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train size: 37562\nTest/Validation size: 9447\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:39:47.792688Z","iopub.execute_input":"2024-10-31T16:39:47.793329Z","iopub.status.idle":"2024-10-31T16:39:47.804199Z","shell.execute_reply.started":"2024-10-31T16:39:47.793290Z","shell.execute_reply":"2024-10-31T16:39:47.803203Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                         clean_query  \\\n0  Сколько официальных языков в США?   \n1  Сколько официальных языков в США?   \n2  Сколько официальных языков в США?   \n3  Сколько официальных языков в США?   \n4  Сколько официальных языков в США?   \n\n                                          clean_text label  \n0  Языки Соединённых Штатов Америки — множество я...     1  \n1  Хотя Соединённые Штаты не имеют на федеральном...     1  \n2  Самый распространённый в США язык — английский...     0  \n3  Официальным языком образования и делопроизводс...     0  \n4  В США в штате Нью-Йорк в 2009 году внесена поп...     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_query</th>\n      <th>clean_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Сколько официальных языков в США?</td>\n      <td>Языки Соединённых Штатов Америки — множество я...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Сколько официальных языков в США?</td>\n      <td>Хотя Соединённые Штаты не имеют на федеральном...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Сколько официальных языков в США?</td>\n      <td>Самый распространённый в США язык — английский...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Сколько официальных языков в США?</td>\n      <td>Официальным языком образования и делопроизводс...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Сколько официальных языков в США?</td>\n      <td>В США в штате Нью-Йорк в 2009 году внесена поп...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train, y_train  = (train['clean_query']+' [SEP] '+train['clean_text']).to_numpy(), train['label'].to_numpy()\nX_test, y_test = (test_val['clean_query']+' [SEP] '+test_val['clean_text']).to_numpy(), test_val['label'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:40:01.823893Z","iopub.execute_input":"2024-10-31T16:40:01.824863Z","iopub.status.idle":"2024-10-31T16:40:01.902643Z","shell.execute_reply.started":"2024-10-31T16:40:01.824821Z","shell.execute_reply":"2024-10-31T16:40:01.901644Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass PandasDataset(Dataset):\n    def __init__(self, df):\n        self.dataframe = df.reset_index()\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        return list(self.dataframe.iloc[index])[1:]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:40:03.010552Z","iopub.execute_input":"2024-10-31T16:40:03.011187Z","iopub.status.idle":"2024-10-31T16:40:03.016643Z","shell.execute_reply.started":"2024-10-31T16:40:03.011147Z","shell.execute_reply":"2024-10-31T16:40:03.015692Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nnum_epochs = 8\nbatch_size = 64\nlearning_rate = 1e-4\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.008)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:40:43.128623Z","iopub.execute_input":"2024-10-31T16:40:43.129541Z","iopub.status.idle":"2024-10-31T16:40:43.638144Z","shell.execute_reply.started":"2024-10-31T16:40:43.129478Z","shell.execute_reply":"2024-10-31T16:40:43.637302Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_dataloader = DataLoader(PandasDataset(pd.DataFrame([X_train, y_train]).T),\n                              batch_size=batch_size)\ntest_dataloader = DataLoader(PandasDataset(pd.DataFrame([X_test, y_test]).T),\n                              batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:40:44.541402Z","iopub.execute_input":"2024-10-31T16:40:44.541809Z","iopub.status.idle":"2024-10-31T16:40:46.282352Z","shell.execute_reply.started":"2024-10-31T16:40:44.541770Z","shell.execute_reply":"2024-10-31T16:40:46.281526Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"writer = SummaryWriter()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:40:46.441413Z","iopub.execute_input":"2024-10-31T16:40:46.442209Z","iopub.status.idle":"2024-10-31T16:40:46.450251Z","shell.execute_reply.started":"2024-10-31T16:40:46.442171Z","shell.execute_reply":"2024-10-31T16:40:46.449461Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import time\n\n# Training loop\ntotal_step = len(train_dataloader)\nbest_val_loss = float('inf')\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_start_time = time.time()  # Start timing the epoch\n    train_loss = 0.0\n    for texts, labels in train_dataloader:\n        loss = model.get_loss(texts, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n        optimizer.step()\n        train_loss += loss.item() * len(texts)  # Accumulate loss\n\n    train_loss /= len(train_dataloader.dataset)  # Compute average loss\n    \n    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n\n    # Evaluate loss after each epoch\n    model.eval()\n    with torch.no_grad():\n        test_loss = sum(model.get_loss(batch[0], batch[1]).item() * len(batch[0]) for batch in test_dataloader) / len(test_dataloader.dataset)\n\n    if test_loss < best_val_loss:\n        best_val_loss = test_loss\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'epoch': epoch,\n            'loss': loss\n        }, 'best_model.ckpt')\n        print('\\nsave_model\\n')\n\n    epoch_duration = time.time() - epoch_start_time  # Calculate epoch duration\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Time: {epoch_duration:.2f} seconds')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:41:51.007961Z","iopub.execute_input":"2024-10-31T16:41:51.008837Z","iopub.status.idle":"2024-10-31T16:57:47.333560Z","shell.execute_reply.started":"2024-10-31T16:41:51.008795Z","shell.execute_reply":"2024-10-31T16:57:47.332415Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\nsave_model\n\nEpoch [1/8], Train Loss: 0.6652, Test Loss: 0.5925, Time: 121.06 seconds\n\nsave_model\n\nEpoch [2/8], Train Loss: 0.6037, Test Loss: 0.5763, Time: 119.97 seconds\nEpoch [3/8], Train Loss: 0.5814, Test Loss: 0.5794, Time: 119.22 seconds\nEpoch [4/8], Train Loss: 0.5763, Test Loss: 0.5809, Time: 119.20 seconds\nEpoch [5/8], Train Loss: 0.5748, Test Loss: 0.5821, Time: 119.26 seconds\nEpoch [6/8], Train Loss: 0.5717, Test Loss: 0.5798, Time: 119.30 seconds\nEpoch [7/8], Train Loss: 0.5710, Test Loss: 0.5784, Time: 119.10 seconds\nEpoch [8/8], Train Loss: 0.5682, Test Loss: 0.5795, Time: 119.20 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"writer.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:57:47.335292Z","iopub.execute_input":"2024-10-31T16:57:47.335614Z","iopub.status.idle":"2024-10-31T16:57:47.340229Z","shell.execute_reply.started":"2024-10-31T16:57:47.335578Z","shell.execute_reply":"2024-10-31T16:57:47.339401Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model2 = Model().to(device)\n\ncheckpoint = torch.load('./best_model.ckpt', weights_only=True)\n\nmodel2.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\n# Если вы планируете использовать модель для обучения\n#model.train()\n\n# Или если планируете использовать только для инференса\nmodel2.eval()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:13:00.593337Z","iopub.execute_input":"2024-10-31T17:13:00.594159Z","iopub.status.idle":"2024-10-31T17:13:01.067511Z","shell.execute_reply.started":"2024-10-31T17:13:00.594120Z","shell.execute_reply":"2024-10-31T17:13:01.066639Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Model(\n  (base): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n      (position_embeddings): Embedding(2048, 312)\n      (token_type_embeddings): Embedding(2, 312)\n      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-2): 3 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=312, out_features=312, bias=True)\n              (key): Linear(in_features=312, out_features=312, bias=True)\n              (value): Linear(in_features=312, out_features=312, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=312, out_features=312, bias=True)\n              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=312, out_features=600, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=600, out_features=312, bias=True)\n            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=312, out_features=312, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (head): Sequential(\n    (dropout): Dropout(p=0.2, inplace=False)\n    (fc_1): Linear(in_features=312, out_features=156, bias=True)\n    (relu_1): ReLU()\n    (batchnorm_1): BatchNorm1d(156, eps=1e-12, momentum=0.1, affine=True, track_running_stats=True)\n    (fc_3): Linear(in_features=156, out_features=2, bias=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def testing(model_f):\n    correct, total = 0, 0\n    with torch.no_grad():\n        for texts, labels in test_dataloader:\n            labels = labels.to(device).long() # Crucial: Convert labels to long\n            tokens = model_f.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n            outputs = model_f(tokens)\n            _, predicted = torch.max(outputs, 1) # Correct way to get predictions\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        print(f'Accuracy: {100 * correct / total:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:13:03.787950Z","iopub.execute_input":"2024-10-31T17:13:03.788826Z","iopub.status.idle":"2024-10-31T17:13:03.795434Z","shell.execute_reply.started":"2024-10-31T17:13:03.788788Z","shell.execute_reply":"2024-10-31T17:13:03.794492Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"testing(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:13:05.546975Z","iopub.execute_input":"2024-10-31T17:13:05.547354Z","iopub.status.idle":"2024-10-31T17:13:27.541466Z","shell.execute_reply.started":"2024-10-31T17:13:05.547317Z","shell.execute_reply":"2024-10-31T17:13:27.540488Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Accuracy: 72.28%\n","output_type":"stream"}]},{"cell_type":"code","source":"testing(model2)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:13:27.542967Z","iopub.execute_input":"2024-10-31T17:13:27.543241Z","iopub.status.idle":"2024-10-31T17:13:49.926701Z","shell.execute_reply.started":"2024-10-31T17:13:27.543211Z","shell.execute_reply":"2024-10-31T17:13:49.925800Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Accuracy: 72.05%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Ranking","metadata":{}},{"cell_type":"code","source":"def custom_metric(df_sorted):\n    n = len(df_sorted)\n    k = df_sorted['label'].sum()\n    if k == 0:\n        return 1\n    top_k = max(3, int(k))\n    \n    top_k_answers = df_sorted.iloc[:top_k]\n    \n    correct_in_top_k = top_k_answers['label'].sum()\n    \n    score = correct_in_top_k / k\n    return score\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:14:03.351521Z","iopub.execute_input":"2024-10-31T17:14:03.352584Z","iopub.status.idle":"2024-10-31T17:14:03.358309Z","shell.execute_reply.started":"2024-10-31T17:14:03.352543Z","shell.execute_reply":"2024-10-31T17:14:03.357398Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def rank_answers_by_relevance(df, model_f):\n    \"\"\"\n    Rank answers based on relevance to a query using a fine-tuned model.\n    :param df: DataFrame with 'query' and 'text' columns\n    :param model_f: The fine-tuned model instance\n    :return: DataFrame with additional 'relevance' column, sorted by relevance\n    \"\"\"\n    relevance_scores = []\n    \n    for _, row in df.iterrows():\n        query = row['clean_query']\n        answer = row['clean_text']\n        \n        # Tokenize using the model's tokenizer\n        inputs = model_f.tokenizer(\n            query,\n            answer,\n            add_special_tokens=True,\n            return_tensors='pt',\n            max_length=512,\n            truncation=True,\n            padding='max_length'\n        ).to(device)\n\n        # Get model prediction and calculate relevance score\n        with torch.no_grad():\n            outputs = model_f(inputs)\n            relevance_score = torch.softmax(outputs, dim=1)[0][1].item()  # Get probability of relevance class\n            relevance_scores.append(relevance_score)\n    \n    # Add relevance scores to DataFrame and sort\n    df['relevance'] = relevance_scores\n    df_sorted = df.sort_values(by='relevance', ascending=False).reset_index(drop=True)\n    \n    return df_sorted\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:14:05.020116Z","iopub.execute_input":"2024-10-31T17:14:05.021086Z","iopub.status.idle":"2024-10-31T17:14:05.030944Z","shell.execute_reply.started":"2024-10-31T17:14:05.021023Z","shell.execute_reply":"2024-10-31T17:14:05.029878Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\nres = []\nfor query, text in df.groupby('clean_query'):\n    ranked_df = rank_answers_by_relevance(text, model)\n    score = custom_metric(ranked_df)\n    n = len(ranked_df)\n    k = ranked_df['label'].sum()\n    res.append([query, score, n, k])\n\nsumm_score = sum([elem[1] for elem in res]) / len(res)\nprint(\"Average Score:\", summ_score)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:14:14.121715Z","iopub.execute_input":"2024-10-31T17:14:14.122679Z","iopub.status.idle":"2024-10-31T17:18:05.043644Z","shell.execute_reply.started":"2024-10-31T17:14:14.122629Z","shell.execute_reply":"2024-10-31T17:18:05.042708Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Average Score: 0.6350554752536202\n","output_type":"stream"}]},{"cell_type":"code","source":"test_val","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:18:05.045153Z","iopub.execute_input":"2024-10-31T17:18:05.045452Z","iopub.status.idle":"2024-10-31T17:18:05.056573Z","shell.execute_reply.started":"2024-10-31T17:18:05.045419Z","shell.execute_reply":"2024-10-31T17:18:05.055657Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                            clean_query  \\\n0                      Где родился Митрополит Вениамин?   \n1                      Где родился Митрополит Вениамин?   \n2                      Где родился Митрополит Вениамин?   \n3                      Где родился Митрополит Вениамин?   \n4                      Где родился Митрополит Вениамин?   \n...                                                 ...   \n9442  Сколько стоит проезд на метро в Москве за одну...   \n9443  Сколько стоит проезд на метро в Москве за одну...   \n9444  Сколько стоит проезд на метро в Москве за одну...   \n9445  Когда был сформирован 130-й Ордена Суворова Ла...   \n9446                         Какая валюта в Казахстане?   \n\n                                             clean_text label  \n0     Митрополит Вениамин (в миру Иван Афанасьевич Ф...     1  \n1     Митрополит Вениамин (, в миру Василий Костаки;...     1  \n2     Митрополит Вениамин (в миру Борис Николаевич П...     1  \n3     Вениамин (в миру Василий Антонович Муратовский...     0  \n4     Архиепископ Вениамин (в миру Вениамин Михайлов...     0  \n...                                                 ...   ...  \n9442  В конце апреля 2018 года Московский метрополит...     0  \n9443  С 2004 по 2011 год стоимость проезда на метро ...     0  \n9444  2 апреля 2013 полностью обновлены тарифы, введ...     0  \n9445  Корпус был сформирован 5 июня 1944 года приказ...     1  \n9446  Казахстанский тенге (; м. р. нескл., произноси...     1  \n\n[9447 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_query</th>\n      <th>clean_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Где родился Митрополит Вениамин?</td>\n      <td>Митрополит Вениамин (в миру Иван Афанасьевич Ф...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Где родился Митрополит Вениамин?</td>\n      <td>Митрополит Вениамин (, в миру Василий Костаки;...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Где родился Митрополит Вениамин?</td>\n      <td>Митрополит Вениамин (в миру Борис Николаевич П...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Где родился Митрополит Вениамин?</td>\n      <td>Вениамин (в миру Василий Антонович Муратовский...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Где родился Митрополит Вениамин?</td>\n      <td>Архиепископ Вениамин (в миру Вениамин Михайлов...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9442</th>\n      <td>Сколько стоит проезд на метро в Москве за одну...</td>\n      <td>В конце апреля 2018 года Московский метрополит...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9443</th>\n      <td>Сколько стоит проезд на метро в Москве за одну...</td>\n      <td>С 2004 по 2011 год стоимость проезда на метро ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9444</th>\n      <td>Сколько стоит проезд на метро в Москве за одну...</td>\n      <td>2 апреля 2013 полностью обновлены тарифы, введ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9445</th>\n      <td>Когда был сформирован 130-й Ордена Суворова Ла...</td>\n      <td>Корпус был сформирован 5 июня 1944 года приказ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9446</th>\n      <td>Какая валюта в Казахстане?</td>\n      <td>Казахстанский тенге (; м. р. нескл., произноси...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9447 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nres = []\nfor query, text in test_val.groupby('clean_query'):\n    ranked_df = rank_answers_by_relevance(text, model2)\n    score = custom_metric(ranked_df)\n    n = len(ranked_df)\n    k = ranked_df['label'].sum()\n    res.append([query, score, n, k])\n\nsumm_score = sum([elem[1] for elem in res]) / len(res)\nprint(\"Average Score:\", summ_score)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:18:05.057669Z","iopub.execute_input":"2024-10-31T17:18:05.058046Z","iopub.status.idle":"2024-10-31T17:18:50.725157Z","shell.execute_reply.started":"2024-10-31T17:18:05.058014Z","shell.execute_reply":"2024-10-31T17:18:50.724205Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Average Score: 0.6346720335126745\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Дообучение после разморозки","metadata":{}},{"cell_type":"code","source":"for param in model2.base.parameters():  # СМОТРИ КАКАЯ МОДЕЛЬ model если не загружал, model2 если загружал\n    param.requires_grad = True\n\n# Reinitialize the optimizer to include all parameters\n# Reduce the learning rate for fine-tuning (suggested value: 1e-5)\nfine_tuning_lr = 1e-4\noptimizer = torch.optim.AdamW(model2.parameters(), lr=fine_tuning_lr, weight_decay=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:00:01.851588Z","iopub.execute_input":"2024-10-30T15:00:01.8525Z","iopub.status.idle":"2024-10-30T15:00:01.85841Z","shell.execute_reply.started":"2024-10-30T15:00:01.852448Z","shell.execute_reply":"2024-10-30T15:00:01.857444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_fine_tune_epochs = 12\ntotal_step = len(train_dataloader)\nbest_val_loss = float('inf')\n\nfor epoch in range(num_fine_tune_epochs):\n    model2.train()\n    epoch_start_time = time.time()  # Start timing the epoch\n    train_loss = 0.0\n    for texts, labels in train_dataloader:\n        loss = model2.get_loss(texts, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model2.parameters(), max_norm=1)\n        optimizer.step()\n        train_loss += loss.item() * len(texts)  # Accumulate loss\n\n    train_loss /= len(train_dataloader.dataset)  # Compute average loss\n\n    # Evaluate loss after each epoch\n    model2.eval()\n    with torch.no_grad():\n        test_loss = sum(model2.get_loss(batch[0], batch[1]).item() * len(batch[0]) for batch in test_dataloader) / len(test_dataloader.dataset)\n\n    if test_loss < best_val_loss:\n        best_val_loss = test_loss\n        torch.save({\n            'model_state_dict': model2.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'epoch': epoch,\n            'loss': loss\n        }, 'best_model_fine_tuned.ckpt')\n        print('\\nsave_model\\n')\n\n    epoch_duration = time.time() - epoch_start_time  # Calculate epoch duration\n    print(f'Epoch [{epoch + 1}/{num_fine_tune_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Time: {epoch_duration:.2f} seconds')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:11:11.663903Z","iopub.execute_input":"2024-10-30T15:11:11.664391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing(model2)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:31:48.992095Z","iopub.execute_input":"2024-10-30T17:31:48.992758Z","iopub.status.idle":"2024-10-30T17:31:49.318263Z","shell.execute_reply.started":"2024-10-30T17:31:48.992717Z","shell.execute_reply":"2024-10-30T17:31:49.316957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = Model().to(device)\n\ncheckpoint = torch.load('best_model_fine_tuned.ckpt', weights_only=True)\n\nmodel3.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nmodel3.eval()\n\ntesting(model3)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:31:49.319103Z","iopub.status.idle":"2024-10-30T17:31:49.319472Z","shell.execute_reply.started":"2024-10-30T17:31:49.319285Z","shell.execute_reply":"2024-10-30T17:31:49.319308Z"},"trusted":true},"execution_count":null,"outputs":[]}]}